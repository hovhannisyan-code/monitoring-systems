# Домашнее задание к занятию "13.Системы мониторинга"

## Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя 
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой 
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?

**Ответ:** CPU (usage, load/core, run queue), память (available, swap), диск (space %, inodes %, I/O latency/queue), сеть (retransmits, rx/tx) — это инфраструктурные узкие места: вычисления грузят CPU, отчёты занимают FS и требуют I/O. На уровне приложения: RPS, доли 2xx/3xx/4xx/5xx, p95/p99 латентности по ключевым эндпоинтам, плюс бизнес-метрики — % успешной генерации отчётов, p95 времени генерации и объём/кол-во сохранённых файлов.

#
2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, 
что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы 
можете ему предложить?

**Ответ:** Дашборд **Service Health** в терминах SLI/SLO: Availability = (2xx+3xx)/all, Latency p95/p99 главных эндпоинтов, Throughput (RPS), “Report success rate” и SLO “95% отчётов ≤ N сек”. Добавить простой глоссарий (“Доступность”, “p95 задержка”, “Ошибка”) и блок “запас по мощностям” (headroom CPU/диск) в понятных процентах.

#
3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою 
очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, 
чтобы разработчики получали ошибки приложения?

**Ответ:** Централизовать системные логи: `rsyslog/journald` → один syslog-хост, шлём только уровни error/critical, алерты по шаблонам (почта/Telegram). Параллельно метрики ошибок (`app_errors_total{type=...}`) в Prometheus для мгновенных оповещений; подробности — в журнале. По возможности — лёгкий self-hosted Sentry-аналог (например, GlitchTip) на существующем сервере.

#
4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. 
Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 
70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

**Ответ:** В формуле учитывали только 2xx. Для доступности 3xx обычно считаются успешными: правильно **(2xx + 3xx) / all**. Также исключите из знаменателя вспомогательные пробы, если это оговорено.
#
5. Опишите основные плюсы и минусы pull и push систем мониторинга.

**Ответ:** **Pull:** централизованный контроль, авто-дискавери, выше доверие к данным; минусы — нужна досягаемость целей/NAT. **Push:** проходит за NAT, удобен для краткоживущих задач; минусы — сложнее аутентификация/надёжность, больше разнородных конфигов на агентах.

#
6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

    - Prometheus 
    - TICK
    - Zabbix
    - VictoriaMetrics
    - Nagios

**Ответ:** 

**Prometheus** — pull (с Pushgateway → гибрид). 

**TICK** — push. 

**Zabbix** — гибрид (активный агент push, пассивный pull). 

**VictoriaMetrics** — гибрид (scrape и remote_write/vmagent).

**Nagios** — преимущественно pull, есть passive checks (гибрид).

#
### 7, 8

![CPU Metrics](https://github.com/hovhannisyan-code/monitoring-systems/blob/master/screenshots/cpu-metrics.png)

### 9

![Docker Metrics](https://github.com/hovhannisyan-code/monitoring-systems/blob/master/screenshots/docker-metrics.png)